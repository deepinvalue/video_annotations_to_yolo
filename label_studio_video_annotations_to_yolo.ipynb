{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "185ba0a1-bb64-478c-9ed4-4c0f41b6c58b",
   "metadata": {},
   "source": [
    "This small project features a notebook that processes video annotations created using Label Studio, converting them into a format suitable for the YOLO object detection model. The script has the capability to interpolate bounding boxes for each individual frame based on key-frame annotations (as needed), and export these labels (i.e., bounding box coordinates), along with the corresponding frames, into a YOLO-compatible format. As it stands with Label Studio version 1.7.0, such functionality isn't inherently available. Please note that video annotations should be exported in the JSON-MIN format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eed6b761-143a-4d68-aac2-45fe04a92867",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json, csv, cv2, copy\n",
    "from decimal import Decimal\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd89e744-cfab-4f2b-aca2-fba66b894874",
   "metadata": {},
   "source": [
    "# Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "03dbf217-dc95-4fe6-b986-54aa6e283158",
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_PATH = 'input/annotations.json'\n",
    "VIDEO_PATH = 'input/video.mp4'\n",
    "OUTPUT_BASE = 'output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bdd62a8c-bb41-4703-be4b-0ad89d3d1aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare YOLO directory structure\n",
    "output_path = Path(OUTPUT_BASE)\n",
    "[(output_path / p).mkdir(parents=True, exist_ok=True) for p in ('images/', 'labels/')];"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51fb23d1-1043-4968-9b9f-8e4b9e9d86b3",
   "metadata": {},
   "source": [
    "# Parsing and Converting Annotations to YOLO Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ddbe112-e4d0-44d6-bad9-a95aa5c6025e",
   "metadata": {},
   "source": [
    "The file should be exported in \"JSON-MIN\" format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d9d99481-01bd-4eee-8e33-42f53cfe0290",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(JSON_PATH) as f:\n",
    "    video_labels = json.load(f, parse_float=Decimal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c8481776-8114-4ad6-a5f8-0740271f20c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = set()\n",
    "\n",
    "for subject in video_labels[0]['box']:\n",
    "    labels.add(*subject['labels'])\n",
    "    \n",
    "labels_dict = {k:i for i,k in enumerate(labels)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fe3dd468-1af6-4931-af56-4c02d3d6ea70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_interpolation(prev_seq, seq, label):\n",
    "    # Define the start and end frame numbers\n",
    "    a0 = prev_seq['frame']\n",
    "    a1 = seq['frame']\n",
    "    frames_info = dict()\n",
    "\n",
    "    # Loop over all intermediate frames\n",
    "    for frame in range(a0+1, a1):\n",
    "        # Calculate the interpolation factor\n",
    "        t = Decimal(frame-a0)/Decimal(a1-a0)\n",
    "        info = [label]\n",
    "\n",
    "        # Interpolate bounding box dimensions for the current frame\n",
    "        for b0, b1 in ((prev_seq[k], seq[k]) for k in ('x', 'y', 'width', 'height')):\n",
    "            info.append(str(b0 + t*(b1-b0)))\n",
    "\n",
    "        # Add interpolated information for the current frame to 'frames_info'\n",
    "        frames_info[frame] = info\n",
    "    return frames_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50099ac6-4d31-4f33-9a83-6abf3dba5771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize dictionaries to store file information and frame timestamps\n",
    "files_dict = dict()\n",
    "frame_times = dict()\n",
    "\n",
    "# Loop over the subjects, i.e. football players in a match\n",
    "for subject in copy.deepcopy(video_labels[0]['box']):\n",
    "    # Get the subject labels (e.g. team-A, team-B, referee, ball)\n",
    "    subject_labels = subject['labels']\n",
    "\n",
    "    # Map the label to its integer representation\n",
    "    if len(subject_labels)==1:\n",
    "        label = labels_dict[subject_labels[0]]\n",
    "    else:\n",
    "        raise ValueError(\"Each subject must have exactly one label.\")\n",
    "    \n",
    "    prev_seq = None\n",
    "    frames = list()\n",
    "    \n",
    "    # Process each sequence in the subject's timeline\n",
    "    for seq in subject['sequence']:\n",
    "        frame = seq['frame']\n",
    "        \n",
    "        # Adjust the x and y coordinates to be the center of the bounding box\n",
    "        seq['x'] += seq['width'] / Decimal('2')\n",
    "        seq['y'] += seq['height'] / Decimal('2')\n",
    "        \n",
    "        # Adjust the scale of bounding box dimensions\n",
    "        for k in ('x', 'y', 'width', 'height'):\n",
    "            seq[k] /= Decimal('100')\n",
    "        \n",
    "        # If the current sequence is not adjacent to the previous sequence, perform linear interpolation\n",
    "        if (prev_seq is not None) and prev_seq['enabled'] and (frame - prev_seq['frame'] > 1):\n",
    "            lines = linear_interpolation(prev_seq, seq, label)\n",
    "        else:\n",
    "            lines = dict()\n",
    "        \n",
    "        # Create the bounding box information line for the current frame\n",
    "        lines[frame] = [label] + [str(seq[k]) for k in ('x', 'y', 'width', 'height')]\n",
    "\n",
    "        # Add the bounding box information line to the corresponding frame in 'files_dict'\n",
    "        for frame, info in lines.items():\n",
    "            if frame in files_dict:\n",
    "                files_dict[frame].append(info)\n",
    "            else:\n",
    "                files_dict[frame] = [info]\n",
    "\n",
    "        # Store the timestamp for the current frame\n",
    "        frame_times.update({frame:float(seq['time'])})\n",
    "        \n",
    "        prev_seq = seq\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e67028f-b8eb-4c08-b186-3e1f405c5b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the file information and frame timestamp dictionaries\n",
    "files_dict = dict(sorted(files_dict.items()))\n",
    "frame_times = dict(sorted(frame_times.items()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "264b4681-e37f-4b5a-bc3d-c34674e5e628",
   "metadata": {},
   "source": [
    "# Exporting the annotations in YOLO Format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144c4bc5-63c8-4f3e-9988-d3c6268959f8",
   "metadata": {},
   "source": [
    "## Writing the Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a203e7c-c9f8-4c09-a0ce-0f1a822e8ac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(output_path / f'classes.txt', 'w') as f:\n",
    "    f.writelines(f'{line}\\n' for line in labels_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40eb10b9-fb82-4ebd-9cad-4e034dd836f5",
   "metadata": {},
   "source": [
    "## Writing the Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3b4bb04c-19c3-4975-9650-e92621ab6c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "for frame, lines in files_dict.items():\n",
    "    with open(output_path / 'labels' / f'frame_{frame:04d}.txt', 'w') as csvfile:\n",
    "        csvwriter = csv.writer(csvfile, delimiter=' ')\n",
    "        csvwriter.writerows(lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "460172d2-b0c2-419f-9381-107b13033903",
   "metadata": {},
   "source": [
    "## Extracting the Frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "87b69fdb-4aaf-4c19-b7cb-796deeb51541",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting 700 frames...\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "vidcap = cv2.VideoCapture(VIDEO_PATH)\n",
    "print(f'Extracting {len(files_dict)} frames...')\n",
    "for frame in files_dict:\n",
    "    vidcap.set(cv2.CAP_PROP_POS_FRAMES, frame-1)\n",
    "    success, image = vidcap.read()\n",
    "    if success:\n",
    "        cv2.imwrite(str(output_path / 'images' / f'frame_{frame:04d}.jpg'), image)\n",
    "    else:\n",
    "        print(f\"Unable to read frame {frame}. Quiting.\")\n",
    "        break\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5de9b43d-a232-4293-8d22-86cec5ad4ff5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
